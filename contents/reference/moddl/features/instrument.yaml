article:
  title: インストゥルメントについて
  content:
    - |
      ここではインストゥルメントについて解説します。

      インストゥルメントは特別な役割を持ったモジュールの一種であり、その名の通り「楽器」に相当するものです。インストゥルメントは ModDL で楽曲を演奏する上で不可欠の存在です。

      インストゥルメントに要求される機能は、周波数の時系列を入力として受け取り、波形を出力することです。さらに、送られてくる Note イベントを処理することも求められます。
      
      インストゥルメントを定義するには `@instrument` 構築文を使います。定義したインストゥルメントは MML を使って演奏することができます。

      ## 最も単純なインストゥルメント

      インストゥルメントは周波数から波形を生成すると述べましたが、この機能はまさにオシレータと同じです。ということは、オシレータを 1 つ置くだけで、「ほぼ」インストゥルメントです。

      ```
      @instrument ^a, sawOsc
      ```

      「ほぼ」と言ったのは、まだ少し足りないからです。これでは音が鳴りっぱなしになってしまいます。たとえば MML の `r` コマンドや `q` コマンドで音を切ろうとしたとき、思ったように切れてくれない結果になります。

      そこで、エンベロープを追加します。エンベロープは Note イベントに反応して、音を出したり止めたりしてくれます。こうなれば、文句なしにインストゥルメントの条件を満たしていると言うことができます。

      ```
      @instrument ^a, sawOsc * adsrEnv
      ```

    - note: 
      - |
        オシレータにエンベロープを適用するには、オシレータの出力に対してエンベロープの出力を**乗算**します。

        次のように、オシレータの出力をエンベロープの入力に**接続**するのではありません：

        ```
        // 音が出ない
        @instrument ^a, sawOsc | adsrEnv
        ```

    - note: 
      - |
        `adsrEnv` は 5 つのパラメータ入力を取りますが、ここでは全て省略してデフォルトのまま使っています。これだけでも note on/off を処理してくれます。

    - |
      ## エフェクトを適用する

      前節で、最も基本的なインストゥルメントを作ることができました。これを出発点に、さらに複雑なインストゥルメントを作ってみましょう。

      何らかの入力を受け取り、加工して出力するモジュール一般を**エフェクト**と呼びます。ここでは、インストゥルメントに何通りかのエフェクトを追加してみます。

    - note:
      - |
        ModDL でエフェクトを実現する機能としてはエフェクトトラックがあり、それを定義するための `@effect` 構築文がありますが、ここではそれらを使いません。エフェクトを適用する対象のインストゥルメントが 1 つだけならエフェクトトラックは不要です。

        詳細は「%link(effect)」を参照してください。

    - |
      ### フィルタ

      まずは、フィルタを適用してみます。

      フィルタは減算合成シンセサイザの基本部品であり、この文脈では「エフェクト」とは認識されていないのが普通かもしれません。

      シンセサイザの構成においては、フィルタはオシレータとエンベロープの間に置かれるのが一般的です。この構成はそのままモジュール定義として記述することができ、次のようになります：

      ```
      @instrument ^a, sawOsc | lpf { freq: 3000, q: 10 } * adsrEnv
      ```

      ここで `freq` はフィルタのカットオフ周波数、`q` は Q 値です。詳細は [Audio EQ Cookbook](https://www.w3.org/TR/audio-eq-cookbook/){target="_blank"} を参照してください。

      フィルタをエンベロープの後に置いてもかまいません（フィルタとエンベロープは順番を入れ替えても結果は変わりません）。ただし、`*` 演算子より `|` 演算子の方が優先度が高いので、括弧が必要になります：

      ```
      @instrument ^a, (sawOsc * adsrEnv) | lpf { freq: 3000, q: 10 }
      ```

      フィルタのパラメータに時間的な変化を加えることもできます。次の例ではカットオフ周波数にエンベロープを接続しています。これによりカットオフ周波数はノートオンの瞬間から 1 秒かけて、6000 Hz から 1000 Hz まで変化します：

      ```
      @instrument ^a, sawOsc | lpf {
        freq: 1000 + 5000 * adsrEnv { decay: 1, sustain: 0 },
        q: 10,
      } * adsrEnv
      ```

      ### ディレイ

      TODO

      ### 歪み

      TODO

      ## インストゥルメントへの入力について

      インストゥルメントに入力される周波数について、もう少し詳しく説明します。

      冒頭で、インストゥルメントには周波数の時系列が入力されると述べましたが、具体的にインストゥルメントの中のどのノードに入力されるかについては明確に説明せず、なんとなくオシレータに入力されるものとして扱ってきました。

      実際そうなのですが、ではどうやって、インストゥルメントを構成する数多のノードの中からオシレータが出力先に選ばれているのでしょうか？　またオシレータに供給される周波数はどこから来るのでしょうか？

      まず供給される周波数の出どころですが、周波数を出力するノードがインストゥルメントの手前にあり、ここが出どころです。<!--周波数の値をコントロールしているのはトラックごとに存在するシーケンサであり、シーケンサのふるまいは MML で定義できます。-->

    - note:
      - |
        このノードは ModDL のソースからは見えません。ノードを設けてオシレータを接続する処理は ModDL 処理系が裏で行っています。

    - |
      そして周波数データが入力される先のノードは、次の条件を満たす全てのノードです：
            
      * ノードの仕様として、主入力を受け付ける
      * 構造において、主入力が割り当たっていない（`|` の右側にない）

      たとえば、次の構造で確認してみます：

      ```
      @instrument ^a, sawOsc | lpf { freq: 4000, q: 3 } * adsrEnv
      ```

      ここに登場するノードを全て挙げると、`sawOsc`, `lpf`, `4000`, `3`, `adsrEnv`, `*` です。このうち主入力を受け付けるものは `sawOsc` と `lpf` ですが、このうち `lpf` は `sawOsc` と接続されているため、すでに主入力が割り当たっています。よって周波数を受け取るのは `sawOsc` のみとなります。

      少し問題を変えてみます。次のようにしてオシレータを 3 つに増やした場合：

      ```
      @instrument ^a, ((sawOsc + pulseOsc) | lpf { freq: 4000, q: 3 } + triangleOsc) * adsrEnv
      ```

      これらのオシレータはモジュール内の様々な位置にありますが、どれも等しく「主入力を受け付けるが主入力が割り当たっていない」状況にあります。したがって周波数はこれら全てに供給され、結果として 3 つのオシレータはユニゾンで発音します。このように、周波数を受け取るノードは複数あってもかまいません。

      ここで `sawOsc` だけ、入力を変えてみます。次のように入力を明示することで実現できます：

      ```
      @instrument ^a, ((440 | sawOsc + pulseOsc) | lpf { freq: 4000, q: 3 } + triangleOsc) * adsrEnv
      ```

      こうすれば `sawOsc` は常に 440 Hz で発音するようになります。主入力が割り当たった `sawOsc` にはもはやシーケンサの周波数は提供されず、シーケンサの周波数が供給されるのは `pulseOsc` と `triangleOsc` の 2 つとなります。

      ## もう一種類のエフェクト：周波数エフェクト

      ここまで述べてきたように、インストゥルメントは周波数を受け取り、波形を出力します。

    - note:
      - |
        ノイズのように、入力周波数を無視するインストゥルメントも考えられますが、ここでは考えないことにします。

    - |
      ということは、インストゥルメントの内部には周波数が波形に変換される「ある点」があり、インストゥルメントはそこを境に、周波数を扱う領域と、波形を扱う領域の 2 つに分かれているはずです。

      「ある点」とは端的に言えばオシレータですが、これまで作ってきたインストゥルメントはほぼ全てオシレータが最初にあったので、周波数を扱う領域には何もなく、全てのエフェクト（エンベロープも含む）はオシレータが出力した波形に対して作用していました。

      しかし、周波数を扱う領域にエフェクトを挿入することもできるはずです。

      実際、そんなエフェクトを作ることができます。波形に変換される前の、周波数の段階で適用するエフェクトなので、このようなエフェクトを**周波数エフェクト**（またはピッチエフェクト）と呼ぶことにします。

      ここからは周波数エフェクトの例をいくつか紹介していきます。

      ### 移調

      入力周波数とは違うキーでインストゥルメントを演奏できると便利な場合があります。全てのインストゥルメントに適用すれば、カラオケのように曲全体を移調することも可能になります。

      音は周波数が 2 倍になると 1 オクターブ高くなる性質があります。したがって 1 オクターブ上に移調したい場合は（この場合「調」は変わらないのであまり移調とはいいませんが…）、入力周波数を 2 倍してやればよいことになります。

      ```
      @instrument ^a, (=f=> 2 * f) | sawOsc * adsrEnv
      ```

    - note:
      - |
        入力された周波数を明示的に扱うため、入力参照構文が必要になります。

    - |
      2 倍ではなく 1.5 倍にすれば、（平均律の音程とは少し異なりますが）完全 5 度上げることができます。

      ```
      @instrument ^a, (=f=> 1.5 * f) | sawOsc * adsrEnv
      ```

      一般には、平均律において周波数を $2^{\frac{s}{12}}$ 倍すれば、半音 $s$ 個分上げることができます（ついでに移調を行うモジュールを変数に切り出しています）。

      ```
      @let :s, 3 // 上げる幅を半音単位で指定する
      @let :transpose, =f=> 2 ^ (s / 12) * f
      @instrument ^a, transpose | sawOsc * adsrEnv
      ```

      このように、オシレータよりも手前にエフェクトを挿入すれば、それは周波数エフェクトとなります。

      ### ビブラート

      オシレータの周波数を、別の遅いオシレータ（LFO）で変調させることでビブラートを表現するのは、シンセサイザの定番です。これをやってみましょう。

      今回、ビブラートの速さを 5 Hz、深さ（本来の周波数からの変位の振幅）を 20 Hz とします。まずは周波数 5 Hz の正弦波（またはお好みで他の波形）を定義します：

      ```
      @let :lfo, 5 | sineOsc
      ```

      これを、インストゥルメントに入力された周波数に振幅 20 で加えてやります：

      ```
      // オシレータの元の振幅が 2 なので、振幅 20 にするには 10 倍する
      @instrument ^a, (=f=> f + 10 * lfo) | sawOsc * adsrEnv
      ```

    - note:
      - |
        この方法では、ビブラートの深さは入力周波数が低いほど深く、高いほど浅くなります。音域に依らず均等にビブラートをかけたい場合は、`lfo` を入力周波数に加算ではなく乗算で適用する必要があります。

    - |
      ### グライド

      グライドはポルタメントとも呼ばれています。グライドは標準ライブラリに `glide` として含まれています。

      グライドは、入力周波数が一定のときはそのまま出力しますが、入力周波数が変化したときに、新しい入力周波数をすぐには出力に反映せず、入力に出力をゆっくり近づけていきます。

      モジュール定義 `glide` は、パラメータ入力として「半減期」（half-life）を取るようになっています。単位は秒であり、入力周波数が $f_1$ から $f_2$ に変化したとき、出力周波数が $\frac{f_1 + f_2}{2}$ に達するのにかかる時間を指定します。

      半減期という用語からわかるように、出力周波数は指数的に変化します。このため厳密には入力と出力が完全に等しくなることは永久にないのですが、聴覚上、また計算精度上、「そのうち」等しくなると考えて問題はありません。

      ```
      @instrument ^a, glide { halflife: 0.1 } | sawOsc * adsrEnv
      ```

      ### その他

      通常は波形エフェクト（いわゆる普通のエフェクト）であるものを周波数エフェクトに使い回すと、様々な可能性があるはずです。

      たとえば周波数に `adsrEnv` を適用すると、癖のあるピッチ変化を実現できるはずです。これはドラム音などの表現に有用かもしれません。

      君だけの周波数エフェクトを作ろう！
